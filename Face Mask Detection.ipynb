{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Mask Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "At the beginning of 2020, the COVID-19 epidemic has swept the world. In order to effectively prevent infection and continuous spread of the epidemic, various countries around the world have invested in a variety of AI vision anti-epidemic measures to urge people to protect themselves and others.\n",
    "\n",
    "Face Mask Detection is one of the most important aspects.\n",
    "\n",
    "This Face Mask Detection Project built with OpenCV, TensorFlow using Deep Learning and Maching Learning Classifier to detect face masks in images, videos and in real-time video streams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "This dataset consists of 3835 images belonging to two classes:\n",
    "\n",
    "with_mask: 1916 images\n",
    "without_mask: 1919 images\n",
    "\n",
    "Source:\n",
    "- [Real-World Masked Face Datasetï¼ŒRMFD](https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset)\n",
    "- [Face-Mask-Detection](https://github.com/chandrikadeb7/Face-Mask-Detection/tree/master/dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dnn_model\n",
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "\n",
    "def detect_img(net, image):\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), (104.0, 177.0, 123.0), False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    return detections\n",
    "\n",
    "def crop_img(image, detections, dim):\n",
    "    h, w, c = image.shape\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.6:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            crop_img = image[startY:endY, startX:endX]\n",
    "            crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "            return crop_img\n",
    "            \n",
    "            \n",
    "def show_detections(image, detections, dim, clf):\n",
    "    h, w, c = image.shape\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.6:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            \n",
    "            crop_img = image[startY:endY, startX:endX]\n",
    "            crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(crop_img, dim, interpolation = cv2.INTER_AREA)\n",
    "            resized = resized.astype('float32')\n",
    "#             plt.imshow(resized, cmap=plt.get_cmap('gray'))\n",
    "            resized = resized.flatten()\n",
    "            predict = clf.predict([resized])\n",
    "            predict_proba = clf.predict_proba([resized])\n",
    "            print(str(predict==1), predict_proba[0][predict])\n",
    "            confidence = predict_proba[0][predict][0]\n",
    "            \n",
    "            text = str(predict==1) + \"{:.2f}%\".format(confidence * 100)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            \n",
    "            if predict[0]==1:\n",
    "                cv2.rectangle(image, (startX, startY), (endX, endY),(0, 255, 0), 1)\n",
    "                cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.rectangle(image, (startX, startY), (endX, endY),(0, 0, 255), 1)\n",
    "                cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False] [0.68502461]\n"
     ]
    }
   ],
   "source": [
    "# path to dataset\n",
    "with_mask = \"C:/Users/ZIJIE/Documents/Project/with_mask/\"\n",
    "without_mask = \"C:/Users/ZIJIE/Documents/Project/without_mask/\"\n",
    "import joblib\n",
    "clf = joblib.load('clf.model')\n",
    "files = os.listdir(with_mask)\n",
    "filename = random.choice(files)\n",
    "file_path = with_mask + filename\n",
    "width, height = 40, 40\n",
    "dim = (width, height)\n",
    "\n",
    "img = cv2.imread(file_path)\n",
    "detections = detect_img(net, img)\n",
    "img = show_detections(img, detections, dim, clf)\n",
    "cv2.imshow(\"test\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 100 faces\n",
      "loaded 200 faces\n",
      "loaded 300 faces\n",
      "loaded 400 faces\n",
      "loaded 500 faces\n",
      "loaded 600 faces\n",
      "loaded 700 faces\n",
      "loaded 800 faces\n",
      "loaded 900 faces\n",
      "loaded 1000 faces\n",
      "loaded 1100 faces\n",
      "loaded 1200 faces\n",
      "loaded 1300 faces\n",
      "loaded 1400 faces\n",
      "loaded 1500 faces\n",
      "loaded 1600 faces\n",
      "loaded 1680 faces\n",
      "loaded 100 faces\n",
      "loaded 200 faces\n",
      "loaded 300 faces\n",
      "loaded 400 faces\n",
      "loaded 500 faces\n",
      "loaded 600 faces\n",
      "loaded 700 faces\n",
      "loaded 800 faces\n",
      "loaded 900 faces\n",
      "loaded 1000 faces\n",
      "loaded 1100 faces\n",
      "loaded 1200 faces\n",
      "loaded 1300 faces\n",
      "loaded 1400 faces\n",
      "loaded 1500 faces\n",
      "loaded 1600 faces\n",
      "loaded 1700 faces\n",
      "loaded 1800 faces\n",
      "loaded 1900 faces\n",
      "loaded 1916 faces\n"
     ]
    }
   ],
   "source": [
    "# path to dataset\n",
    "with_mask = \"C:/Users/ZIJIE/Documents/Project/with_mask/\"\n",
    "without_mask = \"C:/Users/ZIJIE/Documents/Project/without_mask/\"\n",
    "\n",
    "import os\n",
    "def load_face(path, width, height):\n",
    "    data = []\n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for file in filenames:\n",
    "        file_path = path+file\n",
    "        img = cv2.imread(file_path)\n",
    "#         img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        dim = (width, height)\n",
    "        detections = detect_img(net, img)\n",
    "        img = crop_img(img, detections, dim)\n",
    "        if img is None:\n",
    "            continue\n",
    "        resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        resized = resized.astype('float32')\n",
    "        data.append(resized.flatten())\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print('loaded', count, 'faces')\n",
    "    print('loaded', count, 'faces')\n",
    "    return data\n",
    "\n",
    "data_with_mask = load_face(with_mask, 40,40)\n",
    "data_without_mask = load_face(without_mask, 40,40)\n",
    "data = np.array(data_with_mask + data_without_mask)\n",
    "label = np.array([1] * len(data_with_mask) + [0] * len(data_without_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   14.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Saving model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['clf.model']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fit(X, y_label, n_components):\n",
    "    pca = PCA(n_components=n_components, whiten=True)\n",
    "    svc = SVC(kernel='rbf', class_weight='balanced', probability = True, verbose=True)\n",
    "    model = make_pipeline(pca, svc)\n",
    "    param_grid = {'svc__C': [1,5,10,50], 'svc__gamma':[0.0001, 0.0005, 0.001, 0.005]}\n",
    "    grid = GridSearchCV(model, param_grid, verbose=True, n_jobs=-1)\n",
    "    grid.fit(X, y_label)\n",
    "    model = grid.best_estimator_\n",
    "    return model\n",
    "\n",
    "print('Training...')\n",
    "n_components = 10\n",
    "clf = fit(data, label, n_components)\n",
    "\n",
    "import joblib\n",
    "print(\"Saving model...\")\n",
    "joblib.dump(clf, 'clf.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation...\n",
      "[0.85912882 0.83873957 0.86005561 0.85912882 0.85820204 0.86005561\n",
      " 0.86283596 0.84151993 0.85727525 0.84244671]\n"
     ]
    }
   ],
   "source": [
    "print('Cross-Validation...')\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3)\n",
    "print(cross_val_score(clf, data, label, cv=cv, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application\n",
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "files = os.listdir(with_mask)\n",
    "filename = random.choice(files)\n",
    "file_path = with_mask + filename\n",
    "width, height = 40, 40\n",
    "\n",
    "img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "dim = (width, height)\n",
    "resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "resized = resized.astype('float32')\n",
    "plt.imshow(resized, cmap=plt.get_cmap('gray'))\n",
    "img = resized.flatten()\n",
    "clf.predict([img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dnn_model\n",
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "\n",
    "def detect_img(net, image):\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), (104.0, 177.0, 123.0), False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    return detections\n",
    "\n",
    "def crop_img(image, detections, dim):\n",
    "    h, w, c = image.shape\n",
    "    img = []\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.6:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            crop_img = image[startY:endY, startX:endX]\n",
    "            crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "#             img.append(crop_img)\n",
    "            return crop_img\n",
    "    return img\n",
    "            \n",
    "            \n",
    "def show_detections(image, detections, dim, clf):\n",
    "    h, w, c = image.shape\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.6:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            \n",
    "            crop_img = image[startY:endY, startX:endX]\n",
    "            crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(crop_img, dim, interpolation = cv2.INTER_AREA)\n",
    "            resized = resized.astype('float32')\n",
    "#             plt.imshow(resized, cmap=plt.get_cmap('gray'))\n",
    "            resized = resized.flatten()\n",
    "            predict = clf.predict([resized])\n",
    "            predict_proba = clf.predict_proba([resized])\n",
    "            print(str(predict==1), predict_proba[0][predict])\n",
    "            confidence = predict_proba[0][predict][0]\n",
    "            \n",
    "            text = str(predict==1) + \"{:.2f}%\".format(confidence * 100)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            \n",
    "            if predict[0]==1:\n",
    "                cv2.rectangle(image, (startX, startY), (endX, endY),(0, 255, 0), 1)\n",
    "                cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.rectangle(image, (startX, startY), (endX, endY),(255, 0, 0), 1)\n",
    "                cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 0, 0), 2)\n",
    "    return image\n",
    "\n",
    "files = os.listdir(with_mask)\n",
    "filename = random.choice(files)\n",
    "file_path = with_mask + filename\n",
    "width, height = 40, 40\n",
    "dim = (width, height)\n",
    "\n",
    "img = cv2.imread(file_path)\n",
    "detections = detect_img(net, img)\n",
    "img = show_detections(img, detections, dim, clf)\n",
    "plt.imshow(img, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
