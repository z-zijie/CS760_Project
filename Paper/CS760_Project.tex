\documentclass{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

% ===== PACKAGES =====
\usepackage{xcolor, graphicx, wrapfig}
\usepackage{url, hyperref, dirtree, listings}
\usepackage{courier, lipsum}
\usepackage{amsmath,amssymb}
\usepackage{color}
\usepackage{subfigure}
\usepackage{mdframed}
\usepackage{changepage}
\newmdenv[
  topline=false,
  bottomline=false,
  skipabove=\topsep,
  skipbelow=\topsep
]{siderules}
\renewcommand{\abstractname}{}

% ===== NEW COMMAND =====
\definecolor{light-gray}{gray}{0.95}
\newcommand{\code}[1]{\colorbox{light-gray}{\texttt{#1}}}
\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}

% ===== VARIABLES =====
\def \R{\mathbb{R}}
\def \Pr{\mathbb{P}}
\def \D{{\rm D}}
\def \N{{\rm N}}
\def \xx{{\boldsymbol{\rm x}}}
\def \y{{\rm y}}




% ===== HEADER BOX =====
\newcommand{\lecture}[2]{
\pagestyle{myheadings}
\thispagestyle{plain}
\newpage
\noindent
\begin{center}
\rule{\textwidth}{1.6pt}\vspace*{-\baselineskip}\vspace*{2pt} % Thick horizontal line
\rule{\textwidth}{0.4pt}\\[1\baselineskip] % Thin horizontal line
\vbox{\vspace{2mm}
\hbox to 6.28in { {\bf CS 760: Machine Learning} \hfill Fall 2020 }
\vspace{4mm}
\hbox to 6.28in { {\Large \hfill #1  \hfill} }
\vspace{4mm}
\hbox to 6.28in { {\scshape Authors:}  #2 \hfill }}
\vspace{-2mm}
\rule{\textwidth}{0.4pt}\vspace*{-\baselineskip}\vspace{3.2pt} % Thin horizontal line
\rule{\textwidth}{1.6pt}\\[\baselineskip] % Thick horizontal line
\end{center}
\vspace*{4mm}
}



% =============== DOCUMENT ===============
\begin{document}
\lecture{Face Mask Detection}{Zijie Zhang}

\begin{center}
{\Large {\sf GO GREEN. AVOID PRINTING, OR PRINT 2-SIDED OR MULTIPAGE.}}
\end{center}

\begin{abstract}
Write your abstract here
\end{abstract}

\section{Introduction}
With the global outbreak of COVID-19, it's even more important to have some policy to mitigate risk. For public safety and health, people are recommended to wear face masks and coverings to control the spread of the COVID-19.

In hospitals and various COVID-19 testing places. If only people wearing masks are allowed to enter, the risk of infection for doctors and staff can be reduced. However, if a potential COVID-19 infected person who is not wearing a mask suddenly appears, there is a high risk of infection in face-to-face communication.

At many intersections, pedestrians will gather briefly while waiting for traffic lights. At this time, the risk of COVID-19 spreading among the population is high. But it is impossible to hire a person to stay at the intersection and remind pedestrians to wear masks.

Similarly, requiring Uber drivers and passengers to wear masks at all times can also effectively reduce the spread of the COVID-19. However, it is impossible to supervise the wearing of masks on moving vehicles in real time.

There are many application scenarios such as this. If it is all supervised by manpower, the investment cost is high, and the health risks of the staff are also high.

Therefore, the need for artificial intelligence to determine the wearing of masks came into being. The main idea of this project is to construct a classifier to judge whether the photo cropped from the face detector is wearing a mask.

\section{Related/Similar work}
% This project is mainly inspired by \textbf{Baidu AI development platform - mask wearing detection products}.

% \url{https://ai.baidu.com/tech/body/driver}


% Related/Similar work:
% \begin{enumerate}
%   \item \url{https://github.com/AIZOOTech/FaceMaskDetection}
%   \item \url{https://github.com/chandrikadeb7/Face-Mask-Detection}
%   \item \url{https://arxiv.org/abs/2003.09093}
% \end{enumerate}

\section{Dataset}

  \subsection{Source}
  The data comes from the following sources:
  \begin{enumerate}
    \item \textbf{Real-World Masked Face Dataset, RMFD}\\
          \url{https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset}
    \item \textbf{CASIA-WebFace-Dataset}
  \end{enumerate}
  \subsection{Description}
  \begin{enumerate}
    \item The dataset contains 3400 images, which belong to two categories:
          \begin{enumerate}
            \item \textbf{with\_mask: 1470}
            \item \textbf{without\_mask: 1930}
          \end{enumerate}

    \item Classes:\{'with\_mask', 'without\_mask'\}
    
    \item The directory structure:
          \DTsetlength{0.2em}{1em}{0.2em}{1pt}{3pt}
          \dirtree{%
          .1 .
          .2 dataset.
          .3 with\_mask \ldots{} \begin{minipage}[t]{5cm}
            1470 images{.}
            \end{minipage}.
          .3 without\_mask \ldots{} \begin{minipage}[t]{5cm}
            1930 images{.}
            \end{minipage}.
          }
  \end{enumerate}


\section{Approach}

  \subsection{Pre-processing}
  \begin{enumerate}
    \item Since the shapes of the images in the data set are not the same, the first step of preprocessing is to resize all images to the same shape.(180x180)
    \item Data augmentation:\\
          Due to the small sample size of the data set, over-fitting is prone to occur. Therefore, the operation of data augmentation was added. Generate some effective new data on the basis of existing data by using random transformation. This helps expose the model to more aspects of the data.

          \begin{enumerate}
            \item ColorJitter
            \item RandomRotation
            \item RandomVerticalFlip
            \item RandomHorizontalFlip
          \end{enumerate}
    \item For each RGB image, it has three channels. We can convert it to a [3, 180, 180] \textbf{Tensor}.
    \item For each element in the tensor, its range is [0,255]. We should normalize them.
    \item Data preview:
  \end{enumerate}
  \begin{center}
    \includegraphics[width=15cm]{preview.png}
  \end{center}
  \begin{lstlisting}
  Transforms = transforms.Compose([
      transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),
      transforms.RandomApply(torch.nn.ModuleList([
          transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),
          transforms.RandomRotation(degrees=15),
      ]), p=0.3),
      transforms.RandomVerticalFlip(p=0.1),
      transforms.RandomHorizontalFlip(p=0.1),
      transforms.ToTensor(),
      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
  ])
  \end{lstlisting}
  
  \subsection{Neural Networks Method}
  Generally, Convolutional Neural Networks (CNN) are complex feed forward neural networks. CNNs are used for image classification and recognition because of its high accuracy.

  So the first method is Neural Networks.
  \begin{figure}[!htbp]
    \minipage{0.24\textwidth}
      \includegraphics[width=4cm]{structure1.JPG}
    \endminipage\hfill
    \minipage{0.24\textwidth}
      \includegraphics[width=4cm]{structure2.JPG}
    \endminipage\hfill
    \minipage{0.24\textwidth}
      \includegraphics[width=4cm]{structure4.JPG}
    \endminipage\hfill
    \minipage{0.24\textwidth}
      \includegraphics[width=4cm]{structure3.JPG}
    \endminipage
    \end{figure}
  \begin{enumerate}
    \item The main structure of the neural network consists of two parts: Feature learning and classifier.
    \item The first part includes two \textbf{Conv2d} layer.
    \item The second part is a Full-Connected Network.
  \end{enumerate}
  \begin{lstlisting}
  Net(
    (features): Sequential(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): ReLU(inplace=True)
      (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)
      (6): Dropout(p=0.2, inplace=False)
    )
    (classifier): Sequential(
      (0): Linear(in_features=32400, out_features=128, bias=True)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.2, inplace=False)
      (3): Linear(in_features=128, out_features=2, bias=True)
    )
  )
  \end{lstlisting}

  \subsection{Nearest Neighbors Algorithm}
  Considering the use of K-NN algorithm to achieve face recognition, we can try to use K-NN for mask wearing recognition.
  

  \subsection{Packages}


\section{Results}

  \subsection{Description of experiments}

  \subsection{Comparisons}

  \subsection{Results}


\section{Conclusions and Future Work}

\section{References}


\end{document} 
% This dataset consists of 3835 images belonging to two classes:
% \begin{itemize}
%   \item with\_mask: 1916 images
%   \item without\_mask: 1919 images
% \end{itemize}
% The images used were real images of faces wearing masks. The images were collected from the following sources:
% \begin{enumerate}
%   \item \url{https://github.com/chandrikadeb7/Face-Mask-Detection}
%   \item RMFD dataset(\url{https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset})
%   \item MAFA dataset(\url{https://www.kaggle.com/rahulmangalampalli/mafa-data})
% \end{enumerate}
% The following is the directory structure:
% \DTsetlength{0.2em}{1em}{0.2em}{1pt}{3pt}
%   \dirtree{%
%   .1 .
%   .2 dataset.
%   .3 with\_mask \ldots{} \begin{minipage}[t]{5cm}
%     1916 images{.}
%     \end{minipage}.
%   .3 without\_mask \ldots{} \begin{minipage}[t]{5cm}
%     1919 images{.}
%     \end{minipage}.
%   }

% \section{Approach}

% \subsection{Preprocessing}
% \begin{itemize}
%   \item \code{data\_dir = "../dataset"}\\
%         \code{PATH = list(paths.list\_images(data\_dir))}
%   \item Load images:\\
%         The RGB channel values are in the [0, 255] range. We donâ€™t need all the information of the three color channels, just convert the image to grayscale.
%   \item Rescale all images to the same size.\\
%         \code{image = cv2.imread(img\_path, 0)}\\
%         \code{image = cv2.resize(image, (img\_width, img\_height))}
%   \item Standardize data:\\
%         \code{image = image.flatten()/255.0}
% \end{itemize}

% So far, every image has been transformed into a vector with a length of 50176.
% This will make it more convenient to use PCA to extract the principal components.

% \subsection{Visualize the data}
% \begin{center}
%   \includegraphics[width=10cm]{preview1.png}
% \end{center}

% \subsection{Data augmentation}
% Due to the small number of training samples in this data set, overfitting generally occurs. Data augmentation takes the approach of generating additional training data from existing examples by augmenting them using random transformations that yield believable-looking images. This helps expose the model to more aspects of the data and generalize better.\\
% \begin{center}
%   \includegraphics[width=7cm]{augmentation.png}
% \end{center}


% \subsection{Dimensionality reduction}
% \begin{center}
%   \includegraphics[width=4cm]{pca.png}
% \end{center}

% It can be seen that the picture contains many similar pixels, so referring to the idea of face recognition, we can perform appropriate dimensionality reduction processing through principal component analysis.\\
% \textbf{sklearn.decomposition.PCA} is used here.
% \begin{lstlisting}
% n_components = 15
% pca = PCA(
%   n_components=n_components,
%   svd_solver='randomized',
%   whiten=True
% ).fit(X_train)
% eigenfaces = pca.components_.reshape(
%   (n_components, img_height, img_width)
% )
% X_train_pca = pca.transform(X_train)
% X_test_pca = pca.transform(X_test)
% \end{lstlisting}
% Obviously, after extracting the first 15 main features, we can still clearly distinguish whether people are wearing masks.

% \begin{center}
%   \includegraphics[width=10cm]{eigenfaces.png}
% \end{center}

% \subsection{Classification algorithms}


% \subsubsection{Support Vector Machines}
% I chose C-Support Vector Classification(SVC) with Radial basis function kernel(RBF). Use GridSearchCV to find the optimal SVC parameters C and gamma.
% \textbf{sklearn.model\_selection.GridSearchCV} and \textbf{sklearn.svm.SVC} is used here.
% \begin{lstlisting}
% param_grid = {
%     'C': [1e3, 5e3, 1e4, 5e4, 1e5],
%     'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]
% }
% SVM = GridSearchCV(
%     SVC(kernel='rbf',
%         class_weight='balanced',
%         probability = True,
%         verbose = True
%         ),
%     param_grid,
%     verbose=10,
%     n_jobs=-1
% )
% SVM = SVM.fit(X_train_pca, y_train)
% print(SVM.best_estimator_)
% \end{lstlisting}

% \subsubsection{Nearest Neighbors}
% For the n\_components, consider the nearest neighbor classifier.

% \subsubsection{Decision Trees}

% \subsubsection{Bayesian Learning}

% \subsubsection{Logistic Regression}


% \section{Results}


% \section{Conclusions and Future Work}


% \section{References}

% \end{document} 
































